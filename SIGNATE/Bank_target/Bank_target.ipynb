{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ライブラリ読み込み"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "dlopen(/Users/takumu/VScode/.venv/lib/python3.9/site-packages/lightgbm/lib_lightgbm.so, 0x0006): Library not loaded: /usr/local/opt/libomp/lib/libomp.dylib\n  Referenced from: <D21A7969-4567-3BC7-94ED-6A9E83AE9D78> /Users/takumu/VScode/.venv/lib/python3.9/site-packages/lightgbm/lib_lightgbm.so\n  Reason: tried: '/usr/local/opt/libomp/lib/libomp.dylib' (no such file), '/System/Volumes/Preboot/Cryptexes/OS/usr/local/opt/libomp/lib/libomp.dylib' (no such file), '/usr/local/opt/libomp/lib/libomp.dylib' (no such file), '/usr/lib/libomp.dylib' (no such file, not in dyld cache)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32m/Users/takumu/VScode/VScode/SIGNATE/Bank_target/Bank_target.ipynb セル 2\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/takumu/VScode/VScode/SIGNATE/Bank_target/Bank_target.ipynb#W1sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlinear_model\u001b[39;00m \u001b[39mimport\u001b[39;00m LogisticRegression\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/takumu/VScode/VScode/SIGNATE/Bank_target/Bank_target.ipynb#W1sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msvm\u001b[39;00m \u001b[39mimport\u001b[39;00m SVC\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/takumu/VScode/VScode/SIGNATE/Bank_target/Bank_target.ipynb#W1sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mlightgbm\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mlgb\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/takumu/VScode/VScode/SIGNATE/Bank_target/Bank_target.ipynb#W1sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodel_selection\u001b[39;00m \u001b[39mimport\u001b[39;00m train_test_split\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/takumu/VScode/VScode/SIGNATE/Bank_target/Bank_target.ipynb#W1sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodel_selection\u001b[39;00m \u001b[39mimport\u001b[39;00m KFold, cross_val_score, cross_validate\n",
      "File \u001b[0;32m~/VScode/.venv/lib/python3.9/site-packages/lightgbm/__init__.py:8\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[39m\"\"\"LightGBM, Light Gradient Boosting Machine.\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \n\u001b[1;32m      4\u001b[0m \u001b[39mContributors: https://github.com/microsoft/LightGBM/graphs/contributors.\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpathlib\u001b[39;00m \u001b[39mimport\u001b[39;00m Path\n\u001b[0;32m----> 8\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mbasic\u001b[39;00m \u001b[39mimport\u001b[39;00m Booster, Dataset, Sequence, register_logger\n\u001b[1;32m      9\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mcallback\u001b[39;00m \u001b[39mimport\u001b[39;00m early_stopping, log_evaluation, print_evaluation, record_evaluation, reset_parameter\n\u001b[1;32m     10\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mengine\u001b[39;00m \u001b[39mimport\u001b[39;00m CVBooster, cv, train\n",
      "File \u001b[0;32m~/VScode/.venv/lib/python3.9/site-packages/lightgbm/basic.py:110\u001b[0m\n\u001b[1;32m    106\u001b[0m         \u001b[39mraise\u001b[39;00m LightGBMError(lib\u001b[39m.\u001b[39mLGBM_GetLastError()\u001b[39m.\u001b[39mdecode(\u001b[39m'\u001b[39m\u001b[39mutf-8\u001b[39m\u001b[39m'\u001b[39m))\n\u001b[1;32m    107\u001b[0m     \u001b[39mreturn\u001b[39;00m lib\n\u001b[0;32m--> 110\u001b[0m _LIB \u001b[39m=\u001b[39m _load_lib()\n\u001b[1;32m    113\u001b[0m NUMERIC_TYPES \u001b[39m=\u001b[39m (\u001b[39mint\u001b[39m, \u001b[39mfloat\u001b[39m, \u001b[39mbool\u001b[39m)\n\u001b[1;32m    116\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_safe_call\u001b[39m(ret: \u001b[39mint\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/VScode/.venv/lib/python3.9/site-packages/lightgbm/basic.py:101\u001b[0m, in \u001b[0;36m_load_lib\u001b[0;34m()\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(lib_path) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m    100\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m--> 101\u001b[0m lib \u001b[39m=\u001b[39m ctypes\u001b[39m.\u001b[39;49mcdll\u001b[39m.\u001b[39;49mLoadLibrary(lib_path[\u001b[39m0\u001b[39;49m])\n\u001b[1;32m    102\u001b[0m lib\u001b[39m.\u001b[39mLGBM_GetLastError\u001b[39m.\u001b[39mrestype \u001b[39m=\u001b[39m ctypes\u001b[39m.\u001b[39mc_char_p\n\u001b[1;32m    103\u001b[0m callback \u001b[39m=\u001b[39m ctypes\u001b[39m.\u001b[39mCFUNCTYPE(\u001b[39mNone\u001b[39;00m, ctypes\u001b[39m.\u001b[39mc_char_p)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/ctypes/__init__.py:452\u001b[0m, in \u001b[0;36mLibraryLoader.LoadLibrary\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    451\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mLoadLibrary\u001b[39m(\u001b[39mself\u001b[39m, name):\n\u001b[0;32m--> 452\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dlltype(name)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/ctypes/__init__.py:374\u001b[0m, in \u001b[0;36mCDLL.__init__\u001b[0;34m(self, name, mode, handle, use_errno, use_last_error, winmode)\u001b[0m\n\u001b[1;32m    371\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_FuncPtr \u001b[39m=\u001b[39m _FuncPtr\n\u001b[1;32m    373\u001b[0m \u001b[39mif\u001b[39;00m handle \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 374\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_handle \u001b[39m=\u001b[39m _dlopen(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_name, mode)\n\u001b[1;32m    375\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    376\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_handle \u001b[39m=\u001b[39m handle\n",
      "\u001b[0;31mOSError\u001b[0m: dlopen(/Users/takumu/VScode/.venv/lib/python3.9/site-packages/lightgbm/lib_lightgbm.so, 0x0006): Library not loaded: /usr/local/opt/libomp/lib/libomp.dylib\n  Referenced from: <D21A7969-4567-3BC7-94ED-6A9E83AE9D78> /Users/takumu/VScode/.venv/lib/python3.9/site-packages/lightgbm/lib_lightgbm.so\n  Reason: tried: '/usr/local/opt/libomp/lib/libomp.dylib' (no such file), '/System/Volumes/Preboot/Cryptexes/OS/usr/local/opt/libomp/lib/libomp.dylib' (no such file), '/usr/local/opt/libomp/lib/libomp.dylib' (no such file), '/usr/lib/libomp.dylib' (no such file, not in dyld cache)"
     ]
    }
   ],
   "source": [
    "# ライブラリのインポート\n",
    "## データ加工・可視化系ライブラリ\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set(font='IPAexGothic')\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import category_encoders as ce\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OrdinalEncoder, OneHotEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV, learning_curve\n",
    "from sklearn.metrics import classification_report, roc_curve, auc, precision_recall_curve\n",
    "\n",
    "# scikit-learnのインポートをします\n",
    "from sklearn import tree\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold, cross_val_score, cross_validate\n",
    "from sklearn.metrics import accuracy_score, mean_squared_error\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.model_selection import GridSearchCV\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# データ読み込み"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# データのインポート\n",
    "## 学習用データ 13列 11900行、Y列がある\n",
    "train = pd.read_csv('train.csv')\n",
    "## テスト用データ 12列 5100行、Y列がない\n",
    "test = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[\"education\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# default, housing, loan　0-1化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[\"default\"][train[\"default\"] == \"yes\"] = 1\n",
    "train[\"default\"][train[\"default\"] == \"no\"] = 0\n",
    "train[\"default\"] = train[\"default\"].astype(int)\n",
    "train[\"housing\"][train[\"housing\"] == \"yes\"] = 1\n",
    "train[\"housing\"][train[\"housing\"] == \"no\"] = 0\n",
    "train[\"housing\"] = train[\"housing\"].astype(int)\n",
    "train[\"loan\"][train[\"loan\"] == \"yes\"] = 1\n",
    "train[\"loan\"][train[\"loan\"] == \"no\"] = 0\n",
    "train[\"loan\"] = train[\"loan\"].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# dummy変数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dummy = pd.get_dummies(train)\n",
    "train_dummy.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 標準化(age,balance,day,duration,campaign,pdays)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "train_dummy[\"age_std\"] = scaler.fit_transform(train_dummy[[\"age\"]])\n",
    "train_dummy[\"balance_std\"] = scaler.fit_transform(train_dummy[[\"balance\"]])\n",
    "train_dummy[\"day_std\"] = scaler.fit_transform(train_dummy[[\"day\"]])\n",
    "train_dummy[\"duration_std\"] = scaler.fit_transform(train_dummy[[\"duration\"]])\n",
    "train_dummy[\"campaign_std\"] = scaler.fit_transform(train_dummy[[\"campaign\"]])\n",
    "train_dummy[\"pdays_std\"] = scaler.fit_transform(train_dummy[[\"pdays\"]])\n",
    "train_dummy[\"previous_std\"] = scaler.fit_transform(train_dummy[[\"previous\"]])\n",
    "train_dummy_std = train_dummy.drop([\"age\", \"balance\", \"day\", \"duration\", \"campaign\", \"pdays\", \"previous\"], axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 相関行列"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_mat = train_dummy_std.corr(method='pearson')\n",
    "corr_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(corr_mat,\n",
    "            vmin=-1.0,\n",
    "            vmax=1.0,\n",
    "            center=0,\n",
    "            #annot=True, # True:格子の中に値を表示\n",
    "            fmt='.1f',\n",
    "            xticklabels=corr_mat.columns.values,\n",
    "            yticklabels=corr_mat.columns.values,\n",
    "            cmap='coolwarm'\n",
    "           )\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# test_data加工"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test[\"default\"][test[\"default\"] == \"yes\"] = 1\n",
    "test[\"default\"][test[\"default\"] == \"no\"] = 0\n",
    "test[\"default\"] = test[\"default\"].astype(int)\n",
    "test[\"housing\"][test[\"housing\"] == \"yes\"] = 1\n",
    "test[\"housing\"][test[\"housing\"] == \"no\"] = 0\n",
    "test[\"housing\"] = test[\"housing\"].astype(int)\n",
    "test[\"loan\"][test[\"loan\"] == \"yes\"] = 1\n",
    "test[\"loan\"][test[\"loan\"] == \"no\"] = 0\n",
    "test[\"loan\"] = test[\"loan\"].astype(int)\n",
    "\n",
    "test_dummy = pd.get_dummies(test)\n",
    "\n",
    "test_dummy[\"age_std\"] = scaler.fit_transform(test_dummy[[\"age\"]])\n",
    "test_dummy[\"balance_std\"] = scaler.fit_transform(test_dummy[[\"balance\"]])\n",
    "test_dummy[\"day_std\"] = scaler.fit_transform(test_dummy[[\"day\"]])\n",
    "test_dummy[\"duration_std\"] = scaler.fit_transform(test_dummy[[\"duration\"]])\n",
    "test_dummy[\"campaign_std\"] = scaler.fit_transform(test_dummy[[\"campaign\"]])\n",
    "test_dummy[\"pdays_std\"] = scaler.fit_transform(test_dummy[[\"pdays\"]])\n",
    "test_dummy[\"previous_std\"] = scaler.fit_transform(test_dummy[[\"previous\"]])\n",
    "test_dummy_std = test_dummy.drop([\"job_unknown\",\"age\", \"balance\", \"day\", \"duration\", \"campaign\", \"pdays\", \"previous\"], axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 学習(決定木)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scikit-learnのインポートをします\n",
    "from sklearn import tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 「train」の目的変数と説明変数の値を取得\n",
    "target = train_dummy_std[\"y\"].values\n",
    "features = train_dummy_std.drop([\"y\"], axis=1).values\n",
    "# 「test」の説明変数の値を取得\n",
    "test_features = test_dummy_std.values\n",
    " \n",
    "# 決定木の作成とアーギュメントの設定\n",
    "max_depth = 100\n",
    "min_samples_split = 2\n",
    "my_tree_two = tree.DecisionTreeClassifier(max_depth = max_depth, min_samples_split = min_samples_split, random_state = 1)\n",
    "result = my_tree_two\n",
    "my_tree_two = my_tree_two.fit(features, target) \n",
    " \n",
    "\n",
    "# 「test」の説明変数を使って「my_tree_one」のモデルで予測\n",
    "my_prediction = my_tree_two.predict(test_features)\n",
    "result.score(features,target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PassengerIdを取得\n",
    "PassengerId = np.array(test[\"id\"]).astype(int)\n",
    " \n",
    "# my_prediction(予測データ）とPassengerIdをデータフレームへ落とし込む\n",
    "my_solution = pd.DataFrame(my_prediction, PassengerId)\n",
    "display(my_solution.head())\n",
    " \n",
    "# my_tree_one.csvとして書き出し\n",
    "my_solution.to_csv(\"my_tree_one.csv\",header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 学習(ランダムフォレスト)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 決定木の作成とアーギュメントの設定\n",
    "max_depth= 10\n",
    "min_samples_split= 2 \n",
    "n_estimators=50\n",
    "my_tree_two = RandomForestClassifier(max_depth = max_depth, min_samples_split = min_samples_split,n_estimators = n_estimators, random_state = 1)\n",
    "result = my_tree_two\n",
    "my_tree_two = my_tree_two.fit(features, target) \n",
    " \n",
    "\n",
    "# 「test」の説明変数を使って「my_tree_one」のモデルで予測\n",
    "my_prediction = my_tree_two.predict(test_features)\n",
    "result.score(features,target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 学習(ロジスティック分類)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "lr = LogisticRegression()\n",
    "result = lr\n",
    "logistic = lr.fit(features, target) \n",
    " \n",
    "\n",
    "# 「test」の説明変数を使って「my_tree_one」のモデルで予測\n",
    "my_prediction = logistic.predict(test_features)\n",
    "result.score(features,target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PassengerIdを取得\n",
    "PassengerId = np.array(test[\"id\"]).astype(int)\n",
    " \n",
    "# my_prediction(予測データ）とPassengerIdをデータフレームへ落とし込む\n",
    "my_solution = pd.DataFrame(my_prediction, PassengerId)\n",
    "display(my_solution.head())\n",
    " \n",
    "# my_tree_one.csvとして書き出し\n",
    "my_solution.to_csv(\"my_logistic.csv\",header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 学習(SVM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "C = 5\n",
    "kernel = 'rbf'\n",
    "gamma = 1\n",
    "clf = SVC(C=C, kernel=kernel, gamma=gamma)\n",
    "svm = clf.fit(features, target) \n",
    " \n",
    "\n",
    "# 「test」の説明変数を使って「my_tree_one」のモデルで予測\n",
    "my_prediction = svm.predict(test_features)\n",
    "clf.score(features,target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PassengerIdを取得\n",
    "PassengerId = np.array(test[\"id\"]).astype(int)\n",
    " \n",
    "# my_prediction(予測データ）とPassengerIdをデータフレームへ落とし込む\n",
    "my_solution = pd.DataFrame(my_prediction, PassengerId)\n",
    "display(my_solution.head())\n",
    " \n",
    "# my_tree_one.csvとして書き出し\n",
    "my_solution.to_csv(\"my_svm.csv\",header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 学習(LightGBM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "\n",
    "kf  = KFold(n_splits=5, shuffle=True, random_state=1234)\n",
    "accuracies = []\n",
    "\n",
    "for train_index, val_index in kf.split(features):\n",
    "    # モデルと特徴選択器を新たに作成\n",
    "    clf = lgb.LGBMClassifier()\n",
    "\n",
    "    # データ分割\n",
    "    X_train, X_val = features[train_index], features[val_index]\n",
    "    y_train, y_val = target[train_index], target[val_index]\n",
    "\n",
    "    clf.fit(X_train, y_train)\n",
    "    predictions = clf.predict(X_val)\n",
    "\n",
    "    # 精度の計算と保存\n",
    "    accuracy = accuracy_score(y_val, predictions)\n",
    "    accuracies.append(accuracy)\n",
    "    print('Accuracy: %.2f' % accuracy)\n",
    "\n",
    "# 平均精度の計算\n",
    "average_accuracy = sum(accuracies) / len(accuracies)\n",
    "print('Average Accuracy: %.2f' % average_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 交差検証(KFold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf  = KFold(n_splits=5, shuffle=True, random_state=1234)\n",
    "accuracies = []\n",
    "\n",
    "for train_index, val_index in kf.split(features):\n",
    "    # モデルと特徴選択器を新たに作成\n",
    "    model = RandomForestClassifier(n_estimators=100)\n",
    "\n",
    "    # データ分割\n",
    "    X_train, X_val = features[train_index], features[val_index]\n",
    "    y_train, y_val = target[train_index], target[val_index]\n",
    "\n",
    "    model.fit(X_train, y_train)\n",
    "    predictions = model.predict(X_val)\n",
    "\n",
    "    # 精度の計算と保存\n",
    "    accuracy = accuracy_score(y_val, predictions)\n",
    "    accuracies.append(accuracy)\n",
    "    print('Accuracy: %.2f' % accuracy)\n",
    "\n",
    "# 平均精度の計算\n",
    "average_accuracy = sum(accuracies) / len(accuracies)\n",
    "print('Average Accuracy: %.2f' % average_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# グリッドサーチ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "# ランダムフォレストモデルのインスタンス化\n",
    "model = RandomForestClassifier(random_state=1234)\n",
    "\n",
    "# ハイパーパラメータのグリッドを定義\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 150, 200, 250, 300],\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10]\n",
    "}\n",
    "\n",
    "# GridSearchCVの設定\n",
    "grid_search = GridSearchCV(model, param_grid, cv=5, scoring='accuracy',verbose=2)\n",
    "\n",
    "# グリッドサーチの実行\n",
    "grid_search.fit(features, target)\n",
    "\n",
    "# 結果の表示\n",
    "print(\"Best parameters:\", grid_search.best_params_)\n",
    "print(\"Best score:\", grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.6 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "bcc99c1fa2b898aedc4a51d307592b2c1a30bd0b40c0b37e380a430f0712a40b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
